{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We create an instance of a SimpleSkyjoEnv environment, call reset() to initialize the game and list the available agents (players):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from rlskyjo.environment import simple_skyjo_env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"name\": \"skyjo_env\", \"num_players\": 2}\n",
    "env = simple_skyjo_env.env(**cfg)\n",
    "env.reset()\n",
    "\n",
    "env.agents, env.agent_selection\n",
    "\n",
    "def sample_place():\n",
    "    return np.random.randint(0,11)\n",
    "        \n",
    "def sample_draw():\n",
    "    return np.random.randint(12,13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw_player_1\n",
      "12\n",
      "place_player_1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(env.agent_selection)\n",
    "env.step(sample_draw())\n",
    "print(env.agent_selection)\n",
    "env.step(\n",
    "    sample_place()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1302384680.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def agent_to_policy(agent):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0, 16, 16, 16, 16, 16, 16, 10, 16, 16, 16, 16, -4, 10,  2,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  9, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\tx\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\tx\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0, 16, 16, 16, 16, 16, 16, 10, 16, 16, 16, 16, -4, 10,  2,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  9,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 7 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\tx\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\tx\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, 16, 16, 16, 16, 12, 16, 16, 16, 16, -4,  9,  2,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  1, 11, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\tx\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, 16, 16, 16, 16, 12, 16, 16, 16, 16, -4,  9,  2,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  1, 11,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 7 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\tx\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 6\n",
      "6\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16, 16, 16, 16, 16, 10, 16, 16, 16, 16,  3,  9,  2,  0,  2,\n",
      "        0,  0,  0,  0,  0,  0,  2,  0,  1,  1,  1,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16, 16, 16, 16, 16, 10, 16, 16, 16, 16,  3,  9,  2,  0,  2,\n",
      "        0,  0,  0,  0,  0,  0,  2,  0,  1,  1,  1,  0,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 0 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t10]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 7\n",
      "7\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, 16, 16, 16, 16, 12, 16, 16, 16, 16,  3,  9,  2,  0,  3,\n",
      "        0,  0,  0,  0,  0,  0,  2,  0,  1,  1,  1, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, 16, 16, 16, 16, 12, 16, 16, 16, 16,  3,  9,  2,  0,  3,\n",
      "        0,  0,  0,  0,  0,  0,  2,  0,  1,  1,  1, 10,  2], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 2 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [x\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16, 16, 16, 16, 16,  0, 16, 16, 16, 16,  5,  8,  2,  0,  3,\n",
      "        0,  1,  0,  0,  0,  0,  2,  0,  1,  1,  1,  1, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16, 16, 16, 16, 16,  0, 16, 16, 16, 16,  5,  8,  2,  0,  3,\n",
      "        0,  1,  0,  0,  0,  0,  2,  0,  1,  1,  1,  1, 12,  4], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 4 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\tx]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, -2, 16, 16, 16, 12, 16, 16, 16, 16,  5,  8,  2,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  2,  0,  1,  1,  1,  1,  4, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 4 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, -2, 16, 16, 16, 12, 16, 16, 16, 16,  5,  8,  2,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  2,  0,  1,  1,  1,  1,  4, 10], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 10 \n",
      "discard pile top 4 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\tx\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 5\n",
      "5\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  0, 16, 16, 16, 16, 11,  7,  3,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  2,  0,  1,  2,  1,  1, -2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  0, 16, 16, 16, 16, 11,  7,  3,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  2,  0,  1,  2,  1,  1, -2,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 7 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\tx\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, -2, 16, 16, 16, 12, 16, 16,  0, 16, 15,  7,  3,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  3,  1,  1,  2,  1,  1,  8, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  9, 16, -2, 16, 16, 16, 12, 16, 16,  0, 16, 15,  7,  3,  0,  3,\n",
      "        0,  1,  0,  2,  0,  0,  3,  1,  1,  2,  1,  1,  8,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 1 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t-2]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  0, 16, 16,  7, 16, 18,  7,  3,  0,  3,\n",
      "        1,  1,  0,  2,  0,  0,  3,  1,  1,  2,  1,  1, -2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  0, 16, 16,  7, 16, 18,  7,  3,  0,  3,\n",
      "        1,  1,  0,  2,  0,  0,  3,  1,  1,  2,  1,  1, -2,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 3 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t0]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 7\n",
      "7\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  9, 16,  1, 16, 16, 16, 12, 16, 16,  0, 16, 18,  7,  3,  0,  3,\n",
      "        1,  1,  1,  2,  0,  0,  3,  1,  1,  2,  1,  1,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  9, 16,  1, 16, 16, 16, 12, 16, 16,  0, 16, 18,  7,  3,  0,  3,\n",
      "        1,  1,  1,  2,  0,  0,  3,  1,  1,  2,  1,  1,  0,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 0 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\tx\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  3, 16, 16,  7, 16, 18,  6,  3,  0,  4,\n",
      "        1,  1,  1,  2,  0,  0,  3,  1,  2,  2,  1,  1,  9, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  3, 16, 16,  7, 16, 18,  6,  3,  0,  4,\n",
      "        1,  1,  1,  2,  0,  0,  3,  1,  2,  2,  1,  1,  9,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 7 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [x\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 8\n",
      "8\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 16, 16, 16, 12, 10, 16,  0, 16, 18,  6,  3,  0,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  2,  1,  1,  2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 16, 16, 16, 12, 10, 16,  0, 16, 18,  6,  3,  0,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  2,  1,  1,  2, 10], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 10 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [2\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  3,  7, 16,  7, 16, 26,  6,  3,  0,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  3,  1,  1,  2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, 16, 16, 16,  3,  7, 16,  7, 16, 26,  6,  3,  0,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  3,  1,  1,  2, -2], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: -2 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [x\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 10, 16, 16, 12, 10, 16,  0, 16, 26,  5,  4,  1,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  3,  1,  1, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 10, 16, 16, 12, 10, 16,  0, 16, 26,  5,  4,  1,  4,\n",
      "        1,  2,  1,  2,  0,  0,  4,  1,  2,  3,  1,  1, -1,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 3 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t7\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 6\n",
      "6\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, -2, 16, 16,  3,  7, 16,  7, 16, 22,  5,  4,  1,  4,\n",
      "        1,  2,  2,  2,  0,  0,  4,  1,  2,  3,  1,  1,  7, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, -2, 16, 16,  3,  7, 16,  7, 16, 22,  5,  4,  1,  4,\n",
      "        1,  2,  2,  2,  0,  0,  4,  1,  2,  3,  1,  1,  7,  2], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 2 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\tx\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 5\n",
      "5\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 10, 10, 16, 12, 10, 16,  0, 16, 22,  4,  4,  1,  4,\n",
      "        1,  3,  2,  2,  1,  0,  4,  1,  2,  3,  1,  1,  5, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([-1,  0, 16,  1, 10, 10, 16, 12, 10, 16,  0, 16, 22,  4,  4,  1,  4,\n",
      "        1,  3,  2,  2,  1,  0,  4,  1,  2,  3,  1,  1,  5, 11], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 11 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [x\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 0\n",
      "0\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, -2,  2, 16,  3,  7, 16,  7, 16, 28,  4,  4,  2,  4,\n",
      "        1,  3,  2,  2,  1,  0,  4,  1,  2,  3,  2,  1, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7, 16,  4, -2,  2, 16,  3,  7, 16,  7, 16, 28,  4,  4,  2,  4,\n",
      "        1,  3,  2,  2,  1,  0,  4,  1,  2,  3,  2,  1, -1,  5], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 5 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\tx\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 2\n",
      "2\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  1, 10, 10, 16, 12, 10, 16,  0, 16, 33,  3,  4,  2,  4,\n",
      "        1,  3,  2,  2,  2,  0,  4,  1,  2,  3,  3,  1, 11, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t7\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  1, 10, 10, 16, 12, 10, 16,  0, 16, 33,  3,  4,  2,  4,\n",
      "        1,  3,  2,  2,  2,  0,  4,  1,  2,  3,  3,  1, 11,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 1 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t7\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  7,  5,  4, -2,  2, 16,  3,  7, 16,  7, 16, 33,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  0,  4,  1,  2,  3,  3,  1,  1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  7,  5,  4, -2,  2, 16,  3,  7, 16,  7, 16, 33,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  0,  4,  1,  2,  3,  3,  1,  1,  6], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 6 \n",
      "discard pile top 1 \n",
      "======= Player 0 ========== \n",
      " [0\t7\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  1, 10, 10, 16, 12, 10, 16,  0, 16, 32,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  1,  4,  1,  2,  3,  3,  1,  7, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  1, 10, 10, 16, 12, 10, 16,  0, 16, 32,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  1,  4,  1,  2,  3,  3,  1,  7,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 9 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t1]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3,  7, 16,  7, 16, 32,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3,  7, 16,  7, 16, 32,  3,  4,  2,  4,\n",
      "        2,  3,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  1,  2], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 2 \n",
      "discard pile top 1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [7\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 8\n",
      "8\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 27,  3,  4,  2,  4,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  7, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [2\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 27,  3,  4,  2,  4,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  7, -1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: -1 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [2\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\tx\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3,  2, 16,  7, 16, 27,  3,  4,  3,  5,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [2\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t-1\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3,  2, 16,  7, 16, 27,  3,  4,  3,  5,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  0, -1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: -1 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [2\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t-1\t-2]  \n",
      "\n",
      "sampled action 8\n",
      "8\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16, -1, 16, 24,  3,  4,  4,  5,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t-1\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16, -1, 16, 24,  3,  4,  4,  5,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1,  2,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 0 \n",
      "discard pile top 2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t-1\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3, -1, 16,  7, 16, 24,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3, -1, 16,  7, 16, 24,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  3,  3,  3,  1, -1,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 9 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t7\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 26,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  4,  3,  3,  1,  7, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  0,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 26,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  4,  3,  3,  1,  7, 12], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 12 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t0\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3, -1, 16,  9, 16, 26,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  4,  3,  3,  2,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  5,  4, -2,  2, 16,  3, -1, 16,  9, 16, 26,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  1,  4,  3,  3,  2,  0,  8], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 8 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t5\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 2\n",
      "2\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 29,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  2,  4,  3,  3,  2,  5, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 10, 10, 16, 12, 10, 16,  0, 16, 29,  3,  4,  4,  6,\n",
      "        2,  4,  2,  2,  2,  1,  4,  2,  4,  3,  3,  2,  5,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 3 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\tx\t0\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4, -2,  2, 16,  3, -1, 16,  9, 16, 29,  3,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  2,  4,  3,  3,  2, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4, -2,  2, 16,  3, -1, 16,  9, 16, 29,  3,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  2,  4,  3,  3,  2, -1, 10], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 10 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\tx\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 6\n",
      "6\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 10, 10,  3, 12, 10, 16,  0, 16, 39,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  3,  4,  4,  3,  2,  8, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 10, 10,  3, 12, 10, 16,  0, 16, 39,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  3,  4,  4,  3,  2,  8, 12], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 12 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [10\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4, -2,  2, 10,  3, -1, 16,  9, 16, 39,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  3,  4,  4,  3,  3, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4, -2,  2, 10,  3, -1, 16,  9, 16, 39,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  2,  1,  4,  3,  4,  4,  3,  3, 10,  5], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 5 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [-2\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 12, 10,  3, 12, 10, 16,  0, 16, 46,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  3,  1,  4,  3,  4,  4,  3,  3, -2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 12, 10,  3, 12, 10, 16,  0, 16, 46,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  3,  1,  4,  3,  4,  4,  3,  3, -2, 12], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 12 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t0\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1, 16,  9, 16, 46,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  3,  1,  4,  3,  4,  4,  3,  4,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1, 16,  9, 16, 46,  2,  4,  5,  6,\n",
      "        2,  4,  3,  2,  3,  1,  4,  3,  4,  4,  3,  4,  0,  8], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 8 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\tx\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 12, 10,  3, 12, 10,  3, 12, 16, 54,  1,  4,  5,  6,\n",
      "        2,  4,  4,  2,  3,  1,  4,  4,  4,  4,  3,  4,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11, 12,  9,  9, 12, 10,  3, 12, 10,  3, 12, 16, 54,  1,  4,  5,  6,\n",
      "        2,  4,  4,  2,  3,  1,  4,  4,  4,  4,  3,  4,  3,  6], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 6 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t12\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1,  8,  9, 16, 54,  1,  4,  5,  6,\n",
      "        2,  4,  4,  2,  3,  2,  4,  4,  4,  4,  3,  4, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1,  8,  9, 16, 54,  1,  4,  5,  6,\n",
      "        2,  4,  4,  2,  3,  2,  4,  4,  4,  4,  3,  4, 12, -2], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: -2 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  6,  9,  9, 12, 10,  3, 12, 10,  3, 12, 16, 43,  1,  5,  5,  6,\n",
      "        2,  4,  4,  2,  3,  2,  4,  4,  4,  4,  3,  4,  9, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  6,  9,  9, 12, 10,  3, 12, 10,  3, 12, 16, 43,  1,  5,  5,  6,\n",
      "        2,  4,  4,  2,  3,  2,  4,  4,  4,  4,  3,  4,  9,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 3 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t9]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1,  8, -2, 16, 43,  1,  5,  5,  6,\n",
      "        2,  4,  5,  2,  3,  2,  4,  4,  4,  4,  3,  4,  9, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t3]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  5,  2, 10,  3, -1,  8, -2, 16, 43,  1,  5,  5,  6,\n",
      "        2,  4,  5,  2,  3,  2,  4,  4,  4,  4,  3,  4,  9,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 3 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t3]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  6,  9,  3, 12, 10,  3, 12, 10,  3, 12, 16, 40,  1,  5,  5,  6,\n",
      "        2,  4,  6,  2,  3,  2,  4,  4,  4,  4,  3,  4,  6, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t3]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  6,  9,  3, 12, 10,  3, 12, 10,  3, 12, 16, 40,  1,  5,  5,  6,\n",
      "        2,  4,  6,  2,  3,  2,  4,  4,  4,  4,  3,  4,  6, 10], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 10 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t3]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  5,  2, 10,  3, -1,  8, -2, 16, 40,  1,  5,  5,  6,\n",
      "        2,  4,  6,  2,  3,  2,  4,  4,  4,  5,  3,  4,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  5,  2, 10,  3, -1,  8, -2, 16, 40,  1,  5,  5,  6,\n",
      "        2,  4,  6,  2,  3,  2,  4,  4,  4,  5,  3,  4,  3,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 1 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t10\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 6\n",
      "6\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  6,  9, 10, 12, 10,  3, 12, 10,  3, 12, 16, 31,  1,  5,  5,  6,\n",
      "        3,  4,  6,  2,  3,  2,  4,  4,  4,  5,  3,  4, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  6,  9, 10, 12, 10,  3, 12, 10,  3, 12, 16, 31,  1,  5,  5,  6,\n",
      "        3,  4,  6,  2,  3,  2,  4,  4,  4,  5,  3,  4, 10,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 0 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\tx\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 2\n",
      "2\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  5,  2,  1,  3, -1,  8, -2, 16, 31,  1,  5,  5,  7,\n",
      "        3,  4,  6,  2,  3,  2,  4,  4,  5,  5,  3,  4,  9, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  5,  2,  1,  3, -1,  8, -2, 16, 31,  1,  5,  5,  7,\n",
      "        3,  4,  6,  2,  3,  2,  4,  4,  5,  5,  3,  4,  9,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 7 \n",
      "discard pile top 9 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [5\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  6,  0, 10, 12, 10,  3, 12, 10,  3, 12, 16, 33,  1,  5,  5,  7,\n",
      "        3,  4,  6,  2,  3,  2,  5,  4,  5,  5,  3,  4,  5, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  6,  0, 10, 12, 10,  3, 12, 10,  3, 12, 16, 33,  1,  5,  5,  7,\n",
      "        3,  4,  6,  2,  3,  2,  5,  4,  5,  5,  3,  4,  5,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 3 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t10\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 5\n",
      "5\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  7,  2,  1,  3, -1,  8, -2, 16, 33,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  2,  5,  4,  5,  5,  3,  4, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  3,  8,  4,  7,  2,  1,  3, -1,  8, -2, 16, 33,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  2,  5,  4,  5,  5,  3,  4, 10,  6], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 6 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t3\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  6,  0, 10, 12,  3,  3, 12, 10,  3, 12, 16, 36,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  5,  4,  5,  5,  3,  4,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  6,  0, 10, 12,  3,  3, 12, 10,  3, 12, 16, 36,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  5,  4,  5,  5,  3,  4,  3,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 7 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t6\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  3, -1,  8, -2, 16, 36,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  6,  4,  5,  5,  3,  4,  6, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  3, -1,  8, -2, 16, 36,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  6,  4,  5,  5,  3,  4,  6,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 9 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t3]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 7\n",
      "7\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  7,  0, 10, 12,  3,  3, 12, 10,  3, 12, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  6,  4,  6,  5,  3,  4,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  7,  0, 10, 12,  3,  3, 12, 10,  3, 12, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  3,  6,  4,  6,  5,  3,  4,  3,  6], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 6 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\tx]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 7\n",
      "7\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1,  8, -2, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  4,  6,  4,  6,  5,  3,  5, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1,  8, -2, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  4,  6,  4,  6,  5,  3,  5, 12,  8], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 8 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 2\n",
      "2\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([11,  7,  0, 10, 12,  3,  3,  6, 10,  3, 12, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  4,  6,  5,  6,  5,  3,  5,  8, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([11,  7,  0, 10, 12,  3,  3,  6, 10,  3, 12, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  7,  2,  3,  4,  6,  5,  6,  5,  3,  5,  8,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 3 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [11\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 0\n",
      "0\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1,  8, -2, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  8,  2,  3,  4,  6,  5,  6,  5,  3,  5, 11, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1,  8, -2, 16, 42,  1,  5,  5,  7,\n",
      "        3,  4,  8,  2,  3,  4,  6,  5,  6,  5,  3,  5, 11, -1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: -1 \n",
      "discard pile top 11 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t8\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0, 10, 12,  3,  3,  6, 10,  3, 12, 16, 33,  1,  5,  6,  7,\n",
      "        3,  4,  8,  2,  3,  4,  6,  5,  6,  5,  3,  5,  8, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0, 10, 12,  3,  3,  6, 10,  3, 12, 16, 33,  1,  5,  6,  7,\n",
      "        3,  4,  8,  2,  3,  4,  6,  5,  6,  5,  3,  5,  8,  5], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 5 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t6]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 7\n",
      "7\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1, -1, -2, 16, 33,  1,  5,  6,  7,\n",
      "        3,  4,  8,  2,  4,  4,  6,  5,  6,  5,  3,  5,  6, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  7,  2,  1,  9, -1, -1, -2, 16, 33,  1,  5,  6,  7,\n",
      "        3,  4,  8,  2,  4,  4,  6,  5,  6,  5,  3,  5,  6,  4], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 4 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [7\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0, 10, 12,  3,  3,  5, 10,  3, 12, 16, 30,  1,  5,  6,  7,\n",
      "        3,  4,  8,  3,  4,  4,  6,  5,  6,  5,  3,  5,  7, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0, 10, 12,  3,  3,  5, 10,  3, 12, 16, 30,  1,  5,  6,  7,\n",
      "        3,  4,  8,  3,  4,  4,  6,  5,  6,  5,  3,  5,  7,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 0 \n",
      "discard pile top 7 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t10]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  4,  2,  1,  9, -1, -1, -2, 16, 30,  1,  5,  6,  8,\n",
      "        3,  4,  8,  3,  4,  4,  6,  5,  6,  5,  3,  5, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  4,  4,  2,  1,  9, -1, -1, -2, 16, 30,  1,  5,  6,  8,\n",
      "        3,  4,  8,  3,  4,  4,  6,  5,  6,  5,  3,  5, 10,  3], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 3 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t4]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 3\n",
      "3\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0,  0, 12,  3,  3,  5, 10,  3, 12, 16, 29,  1,  5,  6,  8,\n",
      "        3,  4,  9,  3,  4,  4,  6,  5,  6,  5,  3,  5,  4, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 4 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0,  0, 12,  3,  3,  5, 10,  3, 12, 16, 29,  1,  5,  6,  8,\n",
      "        3,  4,  9,  3,  4,  4,  6,  5,  6,  5,  3,  5,  4,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 9 \n",
      "discard pile top 4 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t12\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1, -1, -2, 16, 29,  1,  5,  6,  8,\n",
      "        3,  4,  9,  3,  4,  4,  6,  5,  7,  5,  3,  5, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1, -1, -2, 16, 29,  1,  5,  6,  8,\n",
      "        3,  4,  9,  3,  4,  4,  6,  5,  7,  5,  3,  5, 12,  4], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 4 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t-1\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0,  0, 12,  3,  3,  5, 10,  3,  9, 16, 34,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  4,  4,  6,  5,  7,  5,  3,  5, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 3,  7,  0,  0, 12,  3,  3,  5, 10,  3,  9, 16, 34,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  4,  4,  6,  5,  7,  5,  3,  5, -1,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 7 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [3\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 0\n",
      "0\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1,  4, -2, 16, 34,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  4,  4,  7,  5,  7,  5,  3,  5,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1,  4, -2, 16, 34,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  4,  4,  7,  5,  7,  5,  3,  5,  3,  5], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 5 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t-2\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0, 12,  3,  3,  5, 10,  3,  9, 16, 41,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  7,  5,  3,  5, -2, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0, 12,  3,  3,  5, 10,  3,  9, 16, 41,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  7,  5,  3,  5, -2, 12], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 12 \n",
      "discard pile top -2 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t3\t9\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1,  4,  5, 16, 41,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  7,  5,  3,  6,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9, -1,  4,  5, 16, 41,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  7,  5,  3,  6,  3,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 9 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [-1\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 8\n",
      "8\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0, 12,  3,  3,  5, 10, 12,  9, 16, 51,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6, -1, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0, 12,  3,  3,  5, 10, 12,  9, 16, 51,  1,  5,  6,  8,\n",
      "        3,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6, -1,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 1 \n",
      "discard pile top -1 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [12\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 4\n",
      "4\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9,  9,  4,  5, 16, 45,  1,  5,  6,  8,\n",
      "        4,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  6,  8,  3,  4,  2,  1,  9,  9,  4,  5, 16, 45,  1,  5,  6,  8,\n",
      "        4,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6, 12,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 1 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t6\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 1\n",
      "1\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  3,  3,  5, 10, 12,  9, 16, 45,  1,  5,  6,  8,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6,  6, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  3,  3,  5, 10, 12,  9, 16, 45,  1,  5,  6,  8,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6,  6,  0], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 0 \n",
      "discard pile top 6 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t3\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 5\n",
      "5\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  1,  8,  3,  4,  2,  1,  9,  9,  4,  5, 16, 42,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6,  3, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  1,  8,  3,  4,  2,  1,  9,  9,  4,  5, 16, 42,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  8,  5,  3,  6,  3,  9], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 9 \n",
      "discard pile top 3 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t5\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5, 10, 12,  9, 16, 42,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  9,  5,  3,  6,  5, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5, 10, 12,  9, 16, 42,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  9,  5,  3,  6,  5, 10], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 10 \n",
      "discard pile top 5 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t12\t9\t-2]  \n",
      "\n",
      "sampled action 9\n",
      "9\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  1,  8,  3,  4,  2,  1,  9,  9,  4,  9, 16, 40,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  9,  6,  3,  6, 12, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t10\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  1,  8,  3,  4,  2,  1,  9,  9,  4,  9, 16, 40,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  4,  7,  5,  9,  6,  3,  6, 12,  6], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 6 \n",
      "discard pile top 12 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t8\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t10\t9\t-2]  \n",
      "\n",
      "sampled action 2\n",
      "2\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5, 10, 10,  9, 16, 40,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  7,  5,  9,  6,  3,  6,  8, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t10\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5, 10, 10,  9, 16, 40,  1,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  7,  5,  9,  6,  3,  6,  8,  8], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 8 \n",
      "discard pile top 8 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [x\t10\t9\t-2]  \n",
      "\n",
      "sampled action 8\n",
      "8\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 0,  1,  6,  3,  4,  2,  1,  9,  9,  4,  9, 16, 48,  0,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  7,  6,  9,  7,  3,  6, 10, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 16 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [8\t10\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_0\n",
      "training fct: {'observation': array([ 0,  1,  6,  3,  4,  2,  1,  9,  9,  4,  9, 16, 48,  0,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  7,  6,  9,  7,  3,  6, 10,  7], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 0 \n",
      "holding card player 0: 7 \n",
      "discard pile top 10 \n",
      "======= Player 0 ========== \n",
      " [0\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [8\t10\t9\t-2]  \n",
      "\n",
      "sampled action 0\n",
      "0\n",
      "observe agent draw_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5,  8, 10,  9, 16, 48,  0,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  8,  6,  9,  7,  3,  6,  0, 16], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 1 \n",
      "holding card player 1: 16 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [7\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [8\t10\t9\t-2]  \n",
      "\n",
      "sampled action 12\n",
      "12\n",
      "observe agent place_player_1\n",
      "training fct: {'observation': array([ 7,  7,  0,  0,  1,  0,  3,  5,  8, 10,  9, 16, 48,  0,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  8,  6,  9,  7,  3,  6,  0,  1], dtype=int8), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int8)} 0 False {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: place by Player 1 \n",
      "holding card player 1: 1 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [7\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [8\t10\t9\t-2]  \n",
      "\n",
      "sampled action 10\n",
      "10\n",
      "observe agent draw_player_0\n",
      "training fct: {'observation': array([ 7,  1,  6,  3,  4,  2,  1,  9,  9,  4,  9, 16, 48,  0,  5,  6,  9,\n",
      "        5,  4,  9,  4,  5,  5,  8,  6,  9,  7,  3,  6,  0,  1], dtype=int8), 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)} 65 True {}\n",
      "======= render board: ===== \n",
      "======= stats ============ \n",
      "next turn: draw by Player 0 \n",
      "holding card player 0: 1 \n",
      "discard pile top 0 \n",
      "======= Player 0 ========== \n",
      " [7\t1\t6\t3]\n",
      " [4\t2\t1\t9]\n",
      " [9\t4\t9\tx]  \n",
      "======= Player 1 ========== \n",
      " [7\t7\t0\t0]\n",
      " [1\t0\t3\t5]\n",
      " [8\t10\t9\t-2]  \n",
      "\n",
      "done 65\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m, reward)\n\u001b[0;32m---> 32\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     34\u001b[0m agent_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/skybo/lib/python3.9/site-packages/pettingzoo/utils/wrappers/order_enforcing.py:49\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     48\u001b[0m     EnvLogger\u001b[38;5;241m.\u001b[39merror_render_before_reset()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender.modes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrender(mode)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "i_episode = 1  \n",
    "agent_iters = 0\n",
    "while i_episode <= 1:\n",
    "    for agent in env.agent_iter(max_iter=600):        \n",
    "        # get observation (state) for current agent:\n",
    "        observation, reward, done, info = env.last()\n",
    "        \n",
    "        print(\"training fct:\", observation, reward, done, info)\n",
    "        # perform q-learning with update_Q_value()\n",
    "        # your code here\n",
    "        \n",
    "        env.render(mode='ansi')\n",
    "        if agent_iters > 600:\n",
    "            break\n",
    "        \n",
    "        # store current state            \n",
    "        if not done: \n",
    "            # choose action using epsilon_greedy_policy()\n",
    "            # your code here    \n",
    "            if agent.startswith(\"draw\"):\n",
    "                action = sample_draw()\n",
    "            else:\n",
    "                action = sample_place()\n",
    "        \n",
    "            print(f\"sampled action {action}\")\n",
    "            env.step(action)\n",
    "        else: \n",
    "            # agent is done\n",
    "            env.step(None)\n",
    "            print('done', reward)\n",
    "            env.render()\n",
    "            break\n",
    "    agent_iters = 0\n",
    "    i_episode  += 1\n",
    "    env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
