{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.rllib.env import PettingZooEnv\n",
    "from rlskyjo.environment import simple_skyjo_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.tune.registry import register_env\n",
    "from gym.spaces import Box\n",
    "from ray.rllib.agents.dqn.dqn_torch_model import DQNTorchModel\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.torch_utils import FLOAT_MAX\n",
    "from supersuit.multiagent_wrappers import pad_action_space_v0\n",
    "\n",
    "torch, nn = try_import_torch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.87.73',\n",
       " 'raylet_ip_address': '172.17.87.73',\n",
       " 'redis_address': '172.17.87.73:26653',\n",
       " 'object_store_address': '/tmp/ray/session_2022-01-27_21-05-49_823098_31263/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-01-27_21-05-49_823098_31263/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-01-27_21-05-49_823098_31263',\n",
       " 'metrics_export_port': 46654,\n",
       " 'node_id': 'f8e10565ffb72de1a96d558f39e184626bb4d6ff26441d0c38682574'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchMaskedActions(DQNTorchModel):\n",
    "    \"\"\"PyTorch version of above ParametricActionsModel.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 obs_space,\n",
    "                 action_space,\n",
    "                 num_outputs,\n",
    "                 model_config,\n",
    "                 name,\n",
    "                 **kw):\n",
    "        DQNTorchModel.__init__(self, obs_space, action_space, num_outputs,\n",
    "                               model_config, name, **kw)\n",
    "\n",
    "        obs_len = obs_space.shape[0]-action_space.n\n",
    "\n",
    "        orig_obs_space = Box(shape=(obs_len,), low=obs_space.low[:obs_len], high=obs_space.high[:obs_len])\n",
    "        self.action_embed_model = TorchFC(orig_obs_space, action_space, action_space.n, model_config, name + \"_action_embed\")\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Extract the available actions tensor from the observation.\n",
    "        print(\"input_dict\",input_dict)\n",
    "        action_mask = input_dict[\"obs\"][\"action_mask\"]\n",
    "\n",
    "        # Compute the predicted action embedding\n",
    "        action_logits, _ = self.action_embed_model({\n",
    "            \"obs\": input_dict[\"obs\"]['observation']\n",
    "        })\n",
    "        # turns probit action mask into logit action mask\n",
    "        inf_mask = torch.clamp(torch.log(action_mask), -1e10, FLOAT_MAX)\n",
    "\n",
    "        return action_logits + inf_mask, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self.action_embed_model.value_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 21:05:52,023\tWARNING deprecation.py:45 -- DeprecationWarning: `get_agent_class` has been deprecated. Use `get_trainer_class` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m deepcopy(get_agent_class(alg_name)\u001b[38;5;241m.\u001b[39m_default_config)\n\u001b[1;32m     16\u001b[0m register_env(env_name,\n\u001b[1;32m     17\u001b[0m              \u001b[38;5;28;01mlambda\u001b[39;00m config: PettingZooEnv(env_creator()))\n\u001b[0;32m---> 19\u001b[0m test_env \u001b[38;5;241m=\u001b[39m PettingZooEnv(\u001b[43menv_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m test_env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_space\u001b[39m\u001b[38;5;124m\"\u001b[39m, obs_space)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36menv_creator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menv_creator\u001b[39m():\n\u001b[0;32m---> 10\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43msimple_skyjo_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_players\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "File \u001b[0;32m~/skybo_rl/rlskyjo/environment/simple_skyjo_env.py:12\u001b[0m, in \u001b[0;36menv\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menv\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 12\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleSkyjoEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# env = wrappers.CaptureStdoutWrapper(env)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# env = wrappers.TerminateIllegalWrapper(env, illegal_reward=-1)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# env = wrappers.AssertOutOfBoundsWrapper(env)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     env \u001b[38;5;241m=\u001b[39m wrappers\u001b[38;5;241m.\u001b[39mOrderEnforcingWrapper(env)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    alg_name = \"DQN\"\n",
    "    env_name  = \"pettingzoo_skyjo\"\n",
    "    ModelCatalog.register_custom_model(\n",
    "        \"pa_model\", TorchMaskedActions\n",
    "    )\n",
    "    # function that outputs the environment you wish to register.\n",
    "\n",
    "    def env_creator():\n",
    "        env = simple_skyjo_env.env(**{\"num_players\": 2})\n",
    "        return env\n",
    "\n",
    "\n",
    "    config = deepcopy(get_agent_class(alg_name)._default_config)\n",
    "\n",
    "    register_env(env_name,\n",
    "                 lambda config: PettingZooEnv(env_creator()))\n",
    "\n",
    "    test_env = PettingZooEnv(env_creator())\n",
    "    obs_space = test_env.observation_space\n",
    "    print(\"obs_space\", obs_space)\n",
    "    act_space = test_env.action_space\n",
    "    print(\"act_space\", act_space)\n",
    "\n",
    "    config[\"multiagent\"] = {\n",
    "        \"policies\": {\n",
    "            \"draw\": (None, obs_space, act_space, {}),\n",
    "            \"place\": (None, obs_space, act_space, {}),\n",
    "        },\n",
    "        \"policy_mapping_fn\": lambda agent_id: agent_id.split(\"_\")[0]\n",
    "    }\n",
    "\n",
    "    config[\"num_gpus\"] = int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\"))\n",
    "    config[\"log_level\"] = \"DEBUG\"\n",
    "    config[\"num_workers\"] = 1\n",
    "    config[\"rollout_fragment_length\"] = 30\n",
    "    config[\"train_batch_size\"] = 200\n",
    "    config[\"horizon\"] = 200\n",
    "    config[\"no_done_at_end\"] = False\n",
    "    config[\"framework\"] = \"torch\"\n",
    "    config[\"model\"] = {\n",
    "        \"custom_model\": \"pa_model\",\n",
    "    }\n",
    "    config['n_step'] = 1\n",
    "\n",
    "    config[\"exploration_config\"] = {\n",
    "        # The Exploration class to use.\n",
    "        \"type\": \"EpsilonGreedy\",\n",
    "        # Config for the Exploration class' constructor:\n",
    "        \"initial_epsilon\": 0.1,\n",
    "        \"final_epsilon\": 0.0,\n",
    "        \"epsilon_timesteps\": 100000,  # Timesteps over which to anneal epsilon.\n",
    "    }\n",
    "    config['hiddens'] = []\n",
    "    config['dueling'] = False\n",
    "    config['env'] = env_name\n",
    "\n",
    "    \n",
    "\n",
    "    tune.run(\n",
    "        alg_name,\n",
    "        name=\"DQN\",\n",
    "        stop={\"timesteps_total\": 10000000},\n",
    "        checkpoint_freq=10,\n",
    "        config=config\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
